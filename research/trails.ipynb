{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23c4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harsh\n"
     ]
    }
   ],
   "source": [
    "print(\"Harsh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fd718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DevStuff\\Medical Chatbot\\End-to-End-Medical-Chatbot-using-llama-2\\mchatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "import time\n",
    "import os\n",
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce90a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d423830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900d9e5",
   "metadata": {},
   "source": [
    "Creating text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c3324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    \n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38715f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the chunk: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunk = text_splitter(extracted_data)\n",
    "print(\"Length of the chunk:\" , len(text_chunk)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f56fee",
   "metadata": {},
   "source": [
    "Downloaind Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8848a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloading_embeddings_model():\n",
    "    embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    return embeddings_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2532c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = downloading_embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ac007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c963ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Vector created by embedding models: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DevStuff\\Medical Chatbot\\End-to-End-Medical-Chatbot-using-llama-2\\mchatbot\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Dimension of Vector created by embedding models:\",len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f65df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import Pinecone as pine_cone\n",
    "pinecone_apikey = \"pcsk_2w4sQk_Rbbxy2NeyJhong1KWnQ4HJrpyLiuTKwqAahqYcAqkXG5smfs9eij44VeCoexwi2\"\n",
    "pc = Pinecone(pinecone_apikey)\n",
    "index = pc.Index(\"medical-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279abed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DevStuff\\Medical Chatbot\\End-to-End-Medical-Chatbot-using-llama-2\\mchatbot\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the Pinecone API key as an environment variable before using langchain_pinecone\n",
    "os.environ[\"PINECONE_API_KEY\"] = pinecone_apikey\n",
    "\n",
    "docsearch = pine_cone.from_texts(\n",
    "    [t.page_content for t in text_chunk],\n",
    "    embeddings,\n",
    "    index_name=\"medical-chatbot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb48aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(id='01f992a0-e611-4422-a212-cb0c10cb3e98', metadata={}, page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of'), Document(id='97432ff0-a5df-49f2-aadb-a6e4dca14afe', metadata={}, page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of'), Document(id='79c039bd-9dd0-4f3b-9edd-af7f60eeb36a', metadata={}, page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of')]\n"
     ]
    }
   ],
   "source": [
    "docsearch = pine_cone.from_existing_index(\"medical-chatbot\",embeddings)\n",
    "\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs =docsearch.similarity_search(query,k=3)\n",
    "print(\"Result\",docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6198ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea59a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5301db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0598718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}  # Make sure this line is included\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bdc017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['\"prompt\"', 'context', 'question'], input_types={}, partial_variables={}, template='\\nUse the following pieces of information to answer the user\\'s question.\\nIf you don\\'t know PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\\nchain_type_kwargs={\"prompt\": PROMPT}the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\n\\nContext: {context}\\nQuestion: {question}\\n\\nOnly return the helpful answer below and nothing else.\\nHelpful answer:\\n'), llm=CTransformers(client=<ctransformers.llm.LLM object at 0x00000283847752D0>, model='model/llama-2-7b-chat.ggmlv3.q4_0.bin', model_type='llama', config={'max_new_tokens': 512, 'temperature': 0.8}), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') return_source_documents=True retriever=VectorStoreRetriever(tags=['Pinecone', 'HuggingFaceEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.Pinecone object at 0x0000028382E335D0>, search_kwargs={'k': 2})\n"
     ]
    }
   ],
   "source": [
    "print(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf5a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DevStuff\\Medical Chatbot\\End-to-End-Medical-Chatbot-using-llama-2\\mchatbot\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  There are many different types of acne, including:\n",
      "* Comedonal acne: This type of acne occurs when dead skin cells and other debris clog pores, causing blackheads and whiteheads.\n",
      "* Inflammatory acne: This type of acne occurs when bacteria enter the pore and cause inflammation, leading to redness, swelling, and painful bumps.\n",
      "Note: The above answer is based on the information provided in the reference text.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Input Prompt: \")\n",
    "    result = qa({\"query\": user_input})  # Use \"query\" instead of \"question\"\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
